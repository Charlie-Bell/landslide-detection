{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "116d5228",
   "metadata": {},
   "source": [
    "Table of contents:\n",
    "\n",
    "1. [Import relevant libraries](#Libraries)\n",
    "2. [Load files](#Load)\n",
    "3. [Append Datasets with level-1 predictions](#Import)\n",
    "4. [NN Model training](#Train)\n",
    "5. [Model predictions](#Predictions)\n",
    "6. [Improve model performance](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49244ef1",
   "metadata": {},
   "source": [
    "<a name = \"Libraries\"></a>\n",
    "## 1. Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d35380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb7d4e",
   "metadata": {},
   "source": [
    "<a name = \"Load\"></a>\n",
    "## 2. Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc04910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_df = pd.read_csv('LGBM_predictions.csv')\n",
    "xgb_df = pd.read_csv('XGB_predictions.csv')\n",
    "catboost_df = pd.read_csv('CatBoost_predictions.csv')\n",
    "stacking_df = pd.read_csv('Stacking_predictions.csv')\n",
    "cnn_df = pd.read_csv('CNN_predictions.csv')\n",
    "\n",
    "lgbm_train_df = pd.read_csv('LGBM_train_predictions.csv')\n",
    "xgb_train_df = pd.read_csv('XGB_train_predictions.csv')\n",
    "catboost_train_df = pd.read_csv('CatBoost_train_predictions.csv')\n",
    "stacking_train_df = pd.read_csv('Stacking_train_predictions.csv')\n",
    "cnn_train_df = pd.read_csv('CNN_train_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352878b7",
   "metadata": {},
   "source": [
    "<a name = \"Import\"></a>\n",
    "## 3. Append Datasets and Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab184e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Train_OHE.csv') # Shuffled\n",
    "train_df = train_df.sort_values('Sample_ID', ascending=True).reset_index(drop=True) # Unshuffled\n",
    "train_df['Predicted_LGBM'] = lgbm_train_df[[\"Label\"]] # Unshuffled\n",
    "train_df['Predicted_XGB'] = xgb_train_df[[\"Label\"]] # Unshuffled\n",
    "train_df['Predicted_CatBoost'] = catboost_train_df[[\"Label\"]] # Unshuffled\n",
    "train_df['Predicted_stack'] = stacking_train_df[[\"Label\"]] # Unshuffled\n",
    "train_df['Predicted_CNN'] = cnn_train_df[[\"Label\"]] # Unshuffled\n",
    "train_df = train_df.sample(frac=1, random_state=2022).reset_index(drop=True) # Shuffled\n",
    "\n",
    "train_y_df = train_df[['Label']]\n",
    "train_y = train_y_df.to_numpy()\n",
    "\n",
    "train_X_df = train_df.drop(['Label', 'Sample_ID'], axis=1)\n",
    "train_X = train_X_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4a9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y).squeeze()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx].float() # Both, the data and model parameters, should have the same dtype.\n",
    "        label = self.y[idx]\n",
    "        return sample, label # returns Tensor([channels, H, W])\n",
    "\n",
    "full_dataset = CustomDataset(train_X, train_y)\n",
    "\n",
    "train_size = int(split_ratio * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, range(train_size))\n",
    "val_dataset = torch.utils.data.Subset(full_dataset, range(train_size, train_size + val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98438553",
   "metadata": {},
   "source": [
    "<a name = \"Train\"></a>\n",
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd742d",
   "metadata": {},
   "source": [
    "#### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3e0541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "StackedNet(\n",
      "  (input): Linear(in_features=355, out_features=3550, bias=True)\n",
      "  (fc1a): Linear(in_features=3550, out_features=3550, bias=True)\n",
      "  (fc1b): Linear(in_features=3550, out_features=3550, bias=True)\n",
      "  (fc1c): Linear(in_features=3550, out_features=3550, bias=True)\n",
      "  (fc1d): Linear(in_features=3550, out_features=3550, bias=True)\n",
      "  (fc1e): Linear(in_features=3550, out_features=3550, bias=True)\n",
      "  (fc2): Linear(in_features=3550, out_features=2244, bias=True)\n",
      "  (fc3): Linear(in_features=2244, out_features=244, bias=True)\n",
      "  (output): Linear(in_features=244, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "fc_size = 3550\n",
    "class StackedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(355, fc_size)\n",
    "        self.fc1a = nn.Linear(fc_size, fc_size)\n",
    "        self.fc1b = nn.Linear(fc_size, fc_size)\n",
    "        self.fc1c = nn.Linear(fc_size, fc_size)\n",
    "        self.fc1d = nn.Linear(fc_size, fc_size)\n",
    "        self.fc1e = nn.Linear(fc_size, fc_size)\n",
    "        self.fc2 = nn.Linear(fc_size, 2244)\n",
    "        self.fc3 = nn.Linear(2244, 244)\n",
    "        self.output = nn.Linear(244, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.fc1a(x))\n",
    "        x = F.relu(self.fc1b(x))\n",
    "        x = F.relu(self.fc1c(x))\n",
    "        x = F.relu(self.fc1d(x))\n",
    "        x = F.relu(self.fc1e(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.output(x)\n",
    "        return x    \n",
    "\n",
    "PATH = 'nn_submission.pth'\n",
    "model = StackedNet()\n",
    "if exists(PATH):   \n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a856a2",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d532a848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,     1] loss: 0.014567\n",
      "[10,     1] loss: 0.006932\n",
      "[15,     1] loss: 0.003552\n",
      "[20,     1] loss: 0.011510\n",
      "[25,     1] loss: 0.002045\n",
      "[30,     1] loss: 0.001578\n",
      "[35,     1] loss: 0.001386\n",
      "[40,     1] loss: 0.011793\n",
      "[45,     1] loss: 0.011910\n",
      "[50,     1] loss: 0.000910\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Both, the data and model parameters, should have the same dtype.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.8)\n",
    "\n",
    "batch_size = 512\n",
    "num_epochs = 100\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, start=0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if epoch % 5 == 4 and i == 0:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss:.6f}')\n",
    "            writer.add_scalar(\"train/loss\", running_loss, epoch)\n",
    "            running_loss = 0.0\n",
    "\n",
    "writer.close()\n",
    "print('Finished Training')\n",
    "\n",
    "PATH = 'nn_submission.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea2e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1649\n",
      "           1       0.71      0.71      0.71       524\n",
      "\n",
      "    accuracy                           0.86      2173\n",
      "   macro avg       0.81      0.81      0.81      2173\n",
      "weighted avg       0.86      0.86      0.86      2173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = 'nn_submission.pth'\n",
    "trained_model = StackedNet()\n",
    "trained_model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "labels = val_dataset[:][1]\n",
    "samples = val_dataset[:][0]\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(samples)\n",
    "    _, val_predictions = torch.max(outputs.data, 1)\n",
    "\n",
    "print(classification_report(labels, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd3c3ae",
   "metadata": {},
   "source": [
    "<a name = \"Predictions\"></a>\n",
    "## 5. Model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2340c89",
   "metadata": {},
   "source": [
    "#### NN test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50649cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Test_OHE.csv')\n",
    "\n",
    "test_X_df = test_df.drop(['Sample_ID'], axis=1)\n",
    "test_X_df['Predicted_LGBM'] = lgbm_df[[\"Label\"]]\n",
    "test_X_df['Predicted_XGB'] = xgb_df[[\"Label\"]]\n",
    "test_X_df['Predicted_CatBoost'] = catboost_df[[\"Label\"]]\n",
    "test_X_df['Predicted_stack'] = stacking_df[[\"Label\"]]\n",
    "test_X_df['Predicted_CNN'] = cnn_df[[\"Label\"]]\n",
    "test_X = test_X_df.to_numpy()\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.from_numpy(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx].float() # Both, the data and model parameters, should have the same dtype.\n",
    "        return sample # returns Tensor([channels, H, W])\n",
    "    \n",
    "test_dataset = TestDataset(test_X)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_outputs = trained_model(test_dataset[:])\n",
    "    _, test_predictions = torch.max(test_outputs.data, 1)\n",
    "\n",
    "pd.DataFrame({'Sample_ID': test_df.Sample_ID, 'Label': test_predictions}).to_csv(\"NN_predictions.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5e809c",
   "metadata": {},
   "source": [
    "<a name = \"Conclusion\"></a>\n",
    "## 6. To improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b5835",
   "metadata": {},
   "source": [
    "- Apply SMOTE and Tomek to the Neural Network, along with using a wider array of models trained under varying hyperparameters and datasets.\n",
    "- Try other Network architectures.\n",
    "- Use stratified cross-validation for the data split.\n",
    "- Try some heavier feature engineering. Generate new features from max, min, range, ratio of max:min, ratios of featureX:featurey, means, medians, calculate metrics for each horizontal and vertical strip, count number of unique categorical features for each category, try binning features into categories.\n",
    "- Plot learning curves to see where improves can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d6f461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID  Label\n",
       "0      10865      1\n",
       "1      10866      0\n",
       "2      10867      0\n",
       "3      10868      0\n",
       "4      10869      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = pd.read_csv(\"NN_predictions.csv\")\n",
    "print(len(foo))\n",
    "foo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ebf8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
